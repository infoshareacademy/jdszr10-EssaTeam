# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f4d-sOHHx1DSZCd1zsWXLxMqTU7sxO4D
"""

!pip install streamlit
!pip install tensorflow
!pip install split-folders
!pip install pillow
!pip install matplotlib

import os
import splitfolders
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt
import streamlit as st
from PIL import Image

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/MyDrive/LEGO'
splitfolders.ratio(path,seed=1337, output="output", ratio=(.8, .2))

train_data_dir = 'output/train'
test_data_dir = 'output/val'

image_width = 64
image_height = 64
batch_size = 200

datagen = ImageDataGenerator(rescale=1./255,
                             rotation_range=20,
                             width_shift_range=0.2,
                             height_shift_range=0.2,
                             shear_range=0.2,
                             zoom_range=0.2,
                             horizontal_flip=True,
                             fill_mode='nearest')

train_generator = datagen.flow_from_directory(
        train_data_dir,
        target_size=(image_width, image_height),
        batch_size=batch_size,
        class_mode='categorical')

test_generator = datagen.flow_from_directory(
        test_data_dir,
        target_size=(image_width, image_height),
        batch_size=batch_size,
        class_mode='categorical')

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=(image_width, image_height, 3)),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=(2,2),padding='same'),
    tf.keras.layers.Dropout(0.3),

    tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=(2,2),padding='same'),
    tf.keras.layers.Dropout(0.3),

    tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=(2,2),padding='same'),
    tf.keras.layers.Dropout(0.5),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(9, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

models_dir = "saved_models"
if not os.path.exists(models_dir):
    os.makedirs(models_dir)

checkpointer = ModelCheckpoint(filepath='saved_models/model.hdf5',
                               monitor='val_accuracy', mode='max',
                               verbose=1, save_best_only=True)
early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)
callbacks=[early_stopping, reduce_lr, checkpointer]

history = model.fit(train_generator, epochs = 20, validation_data = test_generator, callbacks=callbacks)

def plot_train_history(history):
    plt.figure(figsize=(15,5))
    plt.subplot(1,2,1)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Dokładność modelu')
    plt.ylabel('Dokładność')
    plt.xlabel('Epoka')
    plt.legend(['trening', 'walidacja'], loc='upper left')

    plt.subplot(1,2,2)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Strata modelu')
    plt.ylabel('Strata')
    plt.xlabel('Epoka')
    plt.legend(['trening', 'walidacja'], loc='upper left')
    plt.show()

model.load_weights('saved_models/model.hdf5')
plot_train_history(history)

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Strata (training data)')
plt.plot(history.history['val_loss'], label='Strata (validation data)')
plt.title('Strata dla danych treningowych i walidacyjnych')
plt.ylabel('Strata')
plt.xlabel('Epoka')
plt.legend(loc="upper left")

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Dokładność (training data)')
plt.plot(history.history['val_accuracy'], label='Dokładność (validation data)')
plt.title('Dokładność dla danych treningowych i walidacyjnych')
plt.ylabel('Dokładność')
plt.xlabel('Epoka')
plt.legend(loc="upper left")

plt.tight_layout()
plt.show()



